version: '3.8'

# =============================================================================
# Biya Indexer All-in-One 部署配置
# 
# 本配置文件整合了所有中间件服务，适用于单节点部署场景。
# 
# 使用方式:
#   启动: docker-compose -f docker-compose.all-in-one.yaml up -d
#   停止: docker-compose -f docker-compose.all-in-one.yaml down
#   日志: docker-compose -f docker-compose.all-in-one.yaml logs -f
# =============================================================================

networks:
  biya-net:
    name: biya-net
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16

services:
  # ===========================================================================
  # Dragonfly - 高性能 Redis 兼容缓存
  # ===========================================================================
  dragonfly:
    image: docker.dragonflydb.io/dragonflydb/dragonfly:${DRAGONFLY_VERSION:-latest}
    container_name: dragonfly
    hostname: dragonfly
    networks:
      - biya-net
    ports:
      - "${DRAGONFLY_PORT:-6379}:6379"
      - "${DRAGONFLY_ADMIN_PORT:-6380}:6380"
    volumes:
      - dragonfly-data:/data
      - ./logs/dragonfly:/logs
    environment:
      - DRAGONFLY_LOGTOSTDERR=false
      - DRAGONFLY_ALSOLOGTOSTDERR=false
      - DRAGONFLY_MINLOGLEVEL=1
    command: >
      --logtostderr=false
      --alsologtostderr=false
      --minloglevel=1
      --proactor_threads ${DRAGONFLY_THREADS:-4}
      --maxmemory ${DRAGONFLY_MEMORY:-2gb}
      --cache_mode=true
      --dbnum 16
      --dir /data
      --dbfilename dump.rdb
      --save 900 1
      --save 300 10
      --save 60 10000
    ulimits:
      memlock: -1
      nofile: 65535
    shm_size: 512mb
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "-h", "localhost", "-p", "6379", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        compress: "true"

  # ===========================================================================
  # Zookeeper - Kafka 依赖的协调服务
  # ===========================================================================
  zookeeper:
    image: confluentinc/cp-zookeeper:${ZOOKEEPER_VERSION:-7.5.0}
    container_name: zookeeper
    hostname: zookeeper
    networks:
      - biya-net
    ports:
      - "${ZOOKEEPER_PORT:-2181}:2181"
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_INIT_LIMIT: 5
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===========================================================================
  # Kafka - 消息队列
  # ===========================================================================
  kafka:
    image: confluentinc/cp-kafka:${KAFKA_VERSION:-7.5.0}
    container_name: kafka
    hostname: kafka
    networks:
      - biya-net
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "${KAFKA_PORT:-9092}:9092"
      - "${KAFKA_INTERNAL_PORT:-29092}:29092"
    volumes:
      - kafka-data:/var/lib/kafka/data
    environment:
      # Broker 配置
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      
      # 监听器配置
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
      
      # Topic 配置
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: ${KAFKA_AUTO_CREATE_TOPICS:-true}
      KAFKA_NUM_PARTITIONS: ${KAFKA_NUM_PARTITIONS:-3}
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      
      # 日志保留
      KAFKA_LOG_RETENTION_HOURS: ${KAFKA_LOG_RETENTION_HOURS:-168}
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_CLEANUP_POLICY: delete
      KAFKA_DELETE_TOPIC_ENABLE: true
      
      # 性能调优
      KAFKA_COMPRESSION_TYPE: producer
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===========================================================================
  # Kafka UI - Kafka Web 管理界面（可选）
  # ===========================================================================
  kafka-ui:
    image: provectuslabs/kafka-ui:${KAFKA_UI_VERSION:-latest}
    container_name: kafka-ui
    hostname: kafka-ui
    networks:
      - biya-net
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "${KAFKA_UI_PORT:-8080}:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: biya-kafka
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    restart: unless-stopped
    profiles:
      - ui
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===========================================================================
  # ScyllaDB - 高性能 NoSQL 数据库
  # ===========================================================================
  scylla:
    image: scylladb/scylla:${SCYLLA_VERSION:-latest}
    container_name: scylla
    hostname: scylla
    networks:
      - biya-net
    ports:
      - "${SCYLLA_CQL_PORT:-9042}:9042"
      - "${SCYLLA_REST_PORT:-10000}:10000"
      - "${SCYLLA_METRICS_PORT:-9180}:9180"
    volumes:
      - scylla-data:/var/lib/scylla
      - scylla-config:/etc/scylla
    environment:
      - SCYLLA_CLUSTER_NAME=biya-scylla
      - SCYLLA_SEEDS=scylla
      - SCYLLA_DATACENTER=dc1
      - SCYLLA_RACK=rack1
    command: >
      --smp ${SCYLLA_SMP:-2}
      --memory ${SCYLLA_MEMORY:-2G}
      --overprovisioned 1
      --api-address 0.0.0.0
      --listen-address 0.0.0.0
      --rpc-address 0.0.0.0
      --seeds scylla
      --developer-mode 1
    ulimits:
      memlock: -1
      nofile: 200000
    shm_size: 1gb
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "nodetool status | grep -E '^UN|^DN' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# =============================================================================
# 数据卷定义
# =============================================================================
volumes:
  # Dragonfly 数据
  dragonfly-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/dragonfly

  # Zookeeper 数据
  zookeeper-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/zookeeper/data
  zookeeper-logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/zookeeper/logs

  # Kafka 数据
  kafka-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/kafka

  # ScyllaDB 数据
  scylla-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/scylla/data
  scylla-config:
    driver: local

